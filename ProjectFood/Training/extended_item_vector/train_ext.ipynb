{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34cdb7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da182566",
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataLoader.dataset import FoodRatingsDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26d76eb",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fabc64f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users = 226570\n",
    "n_items = 231637\n",
    "# n_item_features = 120910\n",
    "# n_item_features = 231647\n",
    "# n_item_features = 231637\n",
    "n_item_features = 352547\n",
    "\n",
    "# batch_size = 256\n",
    "batch_size = 4086\n",
    "\n",
    "device = \"cuda\"\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    FoodRatingsDataset(\n",
    "        \"../../Preprocessing/processed_dataframes/train.csv\",\n",
    "#         \"../../Preprocessing/processed_dataframes/val.csv\",\n",
    "        \"../../Preprocessing/processed_dataframes/sorted_recipes.csv\",\n",
    "        n_users,\n",
    "        n_items,\n",
    "        has_rating_column=True,\n",
    "    ), \n",
    "    batch_size=batch_size,\n",
    "    num_workers=8,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    FoodRatingsDataset(\n",
    "        \"../../Preprocessing/processed_dataframes/val.csv\",\n",
    "#         \"../../Preprocessing/processed_dataframes/test.csv\",\n",
    "        \"../../Preprocessing/processed_dataframes/sorted_recipes.csv\",\n",
    "        n_users,\n",
    "        n_items,\n",
    "        has_rating_column=True,\n",
    "    ), \n",
    "    batch_size=batch_size,\n",
    "    num_workers=2,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    FoodRatingsDataset(\n",
    "        \"../../Preprocessing/processed_dataframes/test.csv\",\n",
    "        \"../../Preprocessing/processed_dataframes/sorted_recipes.csv\",\n",
    "        n_users,\n",
    "        n_items,\n",
    "        has_rating_column=True,\n",
    "    ), \n",
    "    batch_size=batch_size,\n",
    "    num_workers=10,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4312e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e87d587",
   "metadata": {},
   "outputs": [],
   "source": [
    "preparations_tfidf = sparse.load_npz(\"../../Preprocessing/objects/preparations_tfidf.npz\")\n",
    "tags_matrix = sparse.load_npz(\"../../Preprocessing/objects/tags_matrix.npz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4bccd1e",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c2109e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "arange = torch.arange(batch_size, device=device)\n",
    "ones = torch.ones(batch_size, dtype=torch.float32, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e6cd8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_functions import fit, predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec70208",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bdebbf66ef34fcebf7389098c06c117",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k_gmf=8 k_mlp=8 layers=[16, 32, 16, 8] lr=0.0001 epochs=100\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e28ff190056433cb161caa6320824af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, train_loss: 4.659649948760794, val_loss: 4.616104198026074\n",
      "epoch: 2, train_loss: 4.507797676129347, val_loss: 4.363673293207191\n",
      "epoch: 3, train_loss: 4.054220587677243, val_loss: 3.523313020969687\n",
      "epoch: 4, train_loss: 2.404868172596289, val_loss: 1.6729513822772355\n",
      "epoch: 5, train_loss: 1.6282175643496144, val_loss: 1.5882686502781338\n",
      "epoch: 6, train_loss: 1.5490523246063561, val_loss: 1.5170434004720714\n",
      "epoch: 7, train_loss: 1.4791022742006157, val_loss: 1.4526733593625027\n",
      "epoch: 8, train_loss: 1.415246823285051, val_loss: 1.3934911081683468\n",
      "epoch: 9, train_loss: 1.3563350479418983, val_loss: 1.338782846572298\n",
      "epoch: 10, train_loss: 1.3018943719950622, val_loss: 1.288311022602631\n",
      "epoch: 11, train_loss: 1.25181650123181, val_loss: 1.2421228363559755\n",
      "epoch: 12, train_loss: 1.206213177525969, val_loss: 1.2004037560754799\n",
      "epoch: 13, train_loss: 1.1652852529816609, val_loss: 1.1633767166216946\n",
      "epoch: 14, train_loss: 1.1291796804635046, val_loss: 1.1311222420147697\n",
      "epoch: 15, train_loss: 1.0978373391881877, val_loss: 1.1034777281174146\n",
      "epoch: 16, train_loss: 1.0709368566221964, val_loss: 1.0800368127623408\n",
      "epoch: 17, train_loss: 1.0479486802870845, val_loss: 1.0602336657707205\n",
      "epoch: 18, train_loss: 1.02827000799324, val_loss: 1.0434805683337847\n",
      "epoch: 19, train_loss: 1.0113509799095661, val_loss: 1.0292860226713998\n",
      "epoch: 20, train_loss: 0.9967093399658912, val_loss: 1.0171781131929292\n",
      "epoch: 21, train_loss: 0.9839365330146996, val_loss: 1.0067815106693079\n",
      "epoch: 22, train_loss: 0.9726882560443977, val_loss: 0.9977775276417109\n",
      "epoch: 23, train_loss: 0.962677056305815, val_loss: 0.9899012837489745\n",
      "epoch: 24, train_loss: 0.9536727488096808, val_loss: 0.9829340045074902\n",
      "epoch: 25, train_loss: 0.9454961582575288, val_loss: 0.9767184116487732\n",
      "epoch: 26, train_loss: 0.9380106494185727, val_loss: 0.9711251030723449\n",
      "epoch: 27, train_loss: 0.9311061541754763, val_loss: 0.9660594020979678\n",
      "epoch: 28, train_loss: 0.9247027886935244, val_loss: 0.9614402072098059\n",
      "epoch: 29, train_loss: 0.9187304683259123, val_loss: 0.9572071949379067\n",
      "epoch: 30, train_loss: 0.9131354994944044, val_loss: 0.9533203071203081\n",
      "epoch: 31, train_loss: 0.9078772833468515, val_loss: 0.9497315348202121\n",
      "epoch: 32, train_loss: 0.9029162222227061, val_loss: 0.9464081213860243\n",
      "epoch: 33, train_loss: 0.8982271957454409, val_loss: 0.9433268609084903\n",
      "epoch: 34, train_loss: 0.8937802470639632, val_loss: 0.9404742392837796\n",
      "epoch: 35, train_loss: 0.8895548721059227, val_loss: 0.9378413288313735\n",
      "epoch: 36, train_loss: 0.8855328416304311, val_loss: 0.9353966093974188\n",
      "epoch: 37, train_loss: 0.8816906888805822, val_loss: 0.9331307559379769\n",
      "epoch: 38, train_loss: 0.8780222269349551, val_loss: 0.9310525215873136\n",
      "epoch: 39, train_loss: 0.8745073422859847, val_loss: 0.9291525219717505\n",
      "epoch: 40, train_loss: 0.871129028739886, val_loss: 0.9274296888689267\n",
      "epoch: 41, train_loss: 0.8678808138468399, val_loss: 0.9258451456467344\n",
      "epoch: 42, train_loss: 0.864750861184383, val_loss: 0.9244006752764253\n",
      "epoch: 43, train_loss: 0.8617280581608585, val_loss: 0.9230862090058972\n",
      "epoch: 44, train_loss: 0.858803648864436, val_loss: 0.9219036440433634\n",
      "epoch: 45, train_loss: 0.8559685659624764, val_loss: 0.9208454032381792\n",
      "epoch: 46, train_loss: 0.85320921892684, val_loss: 0.9198871067408582\n",
      "epoch: 47, train_loss: 0.850515068011742, val_loss: 0.9190993752058483\n",
      "epoch: 48, train_loss: 0.8478807860543243, val_loss: 0.9184313851869904\n",
      "epoch: 49, train_loss: 0.8452924559711915, val_loss: 0.9178959996742324\n",
      "epoch: 50, train_loss: 0.8427396641656004, val_loss: 0.9174024503936555\n",
      "epoch: 51, train_loss: 0.840221244055197, val_loss: 0.9170135654189812\n",
      "epoch: 52, train_loss: 0.8377232687920492, val_loss: 0.9167587811032438\n",
      "epoch: 53, train_loss: 0.835238893030063, val_loss: 0.9165999766707673\n",
      "epoch: 54, train_loss: 0.8327568724038473, val_loss: 0.9165087290895934\n",
      "epoch: 55, train_loss: 0.8302760407599877, val_loss: 0.916542451222421\n",
      "epoch: 56, train_loss: 0.8277886647041306, val_loss: 0.9166464969957447\n",
      "epoch: 57, train_loss: 0.825291871141227, val_loss: 0.9168506830935791\n",
      "epoch: 58, train_loss: 0.8227797576747468, val_loss: 0.9171658953072512\n",
      "epoch: 59, train_loss: 0.8202505228588024, val_loss: 0.9175496063656242\n",
      "epoch: 60, train_loss: 0.8177019754103844, val_loss: 0.9180178920566491\n",
      "epoch: 61, train_loss: 0.8151341382157336, val_loss: 0.9185613461074561\n",
      "epoch: 62, train_loss: 0.8125462146169463, val_loss: 0.9191896040978159\n",
      "epoch: 63, train_loss: 0.8099380989484308, val_loss: 0.919893162481356\n",
      "epoch: 64, train_loss: 0.8073099403556568, val_loss: 0.9206820047316936\n",
      "epoch: 65, train_loss: 0.804660537984391, val_loss: 0.9215550944532241\n",
      "epoch: 66, train_loss: 0.8019951369971651, val_loss: 0.9225072669990894\n",
      "epoch: 67, train_loss: 0.799315503740671, val_loss: 0.9235112750969322\n",
      "epoch: 68, train_loss: 0.7966230927417488, val_loss: 0.924572373717573\n",
      "epoch: 69, train_loss: 0.7939194316345655, val_loss: 0.9256966405247729\n",
      "epoch: 70, train_loss: 0.7912050366981005, val_loss: 0.9270892051383777\n",
      "epoch: 71, train_loss: 0.7883397707020986, val_loss: 0.9286789823831987\n",
      "epoch: 72, train_loss: 0.7854916890821327, val_loss: 0.9301236564253161\n",
      "epoch: 73, train_loss: 0.7827111502443462, val_loss: 0.9315753206620122\n",
      "epoch: 74, train_loss: 0.779948230252717, val_loss: 0.9330456632443843\n",
      "epoch: 75, train_loss: 0.7772035872350955, val_loss: 0.9345093779497434\n",
      "epoch: 76, train_loss: 0.7744771540463068, val_loss: 0.9360173707742507\n",
      "epoch: 77, train_loss: 0.7717737713827179, val_loss: 0.9375497650020781\n",
      "epoch: 78, train_loss: 0.769093611494667, val_loss: 0.9391254781234781\n"
     ]
    }
   ],
   "source": [
    "losses_fit = []\n",
    "\n",
    "for run_number, (k_gmf, k_mlp, layers, lr, epochs) in tqdm(enumerate([\n",
    "#     (8, 16, [16, 8], 0.0001, 75),\n",
    "#     (8, 16, [16, 8], 0.0006, 50),\n",
    "#     (8, 16, [16, 8], 0.0008, 50),\n",
    "#     (16, 16, [16, 8], 0.001, 50),\n",
    "#     (16, 32, [32, 16, 8], 0.001, 50),\n",
    "#     (32, 16, [16, 8], 0.0008, 30),\n",
    "#     (32, 16, [16, 8], 0.0001, 50),\n",
    "#     (32, 16, [16, 8], 0.001, 50),\n",
    "#     (4, 8, [8], 0.0005, 50),\n",
    "    (8, 8, [16,32,16,8], 0.0001, 100)\n",
    "#     (32, 16, [16, 8], 0.005, 50),\n",
    "#     (32, 16, [16, 8], 0.01, 50),\n",
    "#     (32, 32, [32, 16, 8], 0.01, 50),\n",
    "#     (32, 32, [32, 16, 8], 0.00001, 100),\n",
    "#     (32, 32, [32, 16, 8], 0.0001, 100),\n",
    "])):\n",
    "    print(f\"{k_gmf=} {k_mlp=} {layers=} {lr=} {epochs=}\")\n",
    "    losses_fit.append(\n",
    "        fit(\n",
    "            train_dataloader, \n",
    "            val_dataloader,\n",
    "            n_users,\n",
    "            n_items,\n",
    "            n_item_features,\n",
    "            k_gmf,\n",
    "            k_mlp,\n",
    "            layers,\n",
    "            preparations_tfidf,\n",
    "            tags_matrix,\n",
    "            arange,\n",
    "            ones,\n",
    "            0.5,\n",
    "            lr,\n",
    "            epochs,\n",
    "            weight_path=\"/home/nubol23/Documents/Project/NCF_dot\",\n",
    "            run_number=run_number,\n",
    "            random_state=3,\n",
    "            show_loss=True,\n",
    "            device=\"cuda\",\n",
    "        )\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
