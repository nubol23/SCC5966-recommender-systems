{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07182b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from typing import List\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fd325c",
   "metadata": {},
   "source": [
    "## Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef0b236d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct(\n",
    "    P: torch.FloatTensor,\n",
    "    Q: torch.FloatTensor,\n",
    "    bu: torch.FloatTensor,\n",
    "    bi: torch.FloatTensor,\n",
    "    mu: float,\n",
    ") -> torch.FloatTensor:\n",
    "    P = P.cuda()\n",
    "    Q = Q.cuda()\n",
    "    bu = bu.cuda()\n",
    "    bi = bi.cuda()\n",
    "    \n",
    "    Bu = torch.concat((bu, torch.ones(len(bu), 1, device=\"cuda\")), dim=1)\n",
    "    Bi = torch.concat((bi, torch.ones(len(bi), 1, device=\"cuda\")), dim=1)\n",
    "    \n",
    "    mat = mu + Bu@Bi.T + P@Q.T\n",
    "    \n",
    "    return torch.clip(mat, 1, 5).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23f77b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(\n",
    "    uir_mat: torch.IntTensor, # User Item rating mat\n",
    "    k: int,\n",
    "    lr: float,\n",
    "    位: float,\n",
    "    iters: int,\n",
    "    n_users: int,\n",
    "    n_movies: int,\n",
    "    mu: float = None,\n",
    "    uir_val: torch.IntTensor = None\n",
    ") -> List[torch.FloatTensor]:\n",
    "    train_losses = np.zeros(iters)\n",
    "    val_losses = np.zeros(iters)\n",
    "    \n",
    "    # Initialize params\n",
    "    uir_mat = uir_mat.cuda()\n",
    "    expected = uir_mat[:, 2].float()\n",
    "    n_interactions = expected.shape[0]\n",
    "    \n",
    "    if uir_val is not None:\n",
    "        uir_val = uir_val.cuda()\n",
    "        expected_val = uir_val[:, 2].float()\n",
    "        n_interactions_val = expected_val.shape[0]\n",
    "    \n",
    "    P = torch.rand(n_users, k, requires_grad=True, device=\"cuda\")\n",
    "    Q = torch.rand(n_movies, k, requires_grad=True, device=\"cuda\")\n",
    "    with torch.no_grad():\n",
    "        P *= .1\n",
    "        Q *= .1\n",
    "    bu = torch.rand(n_users, 1, requires_grad=True, device=\"cuda\")\n",
    "    bi = torch.rand(n_movies, 1, requires_grad=True, device=\"cuda\")\n",
    "    \n",
    "    if mu is None:\n",
    "        mu = (expected.sum()/(expected!=0).sum())\n",
    "\n",
    "#     criterion = nn.MSELoss()\n",
    "    \n",
    "    # Fit\n",
    "    ones_user = torch.ones(n_users, 1, requires_grad=False, device=\"cuda\")\n",
    "    ones_item = torch.ones(n_movies, 1, requires_grad=False, device=\"cuda\")\n",
    "\n",
    "    min_loss = torch.inf\n",
    "    params = []\n",
    "    \n",
    "    val_loss = torch.inf\n",
    "    for i in tqdm(range(iters)):\n",
    "        Bu = torch.concat((bu, ones_user), dim=1)\n",
    "        Bi = torch.concat((ones_item, bi), dim=1)\n",
    "\n",
    "        pred_mat = mu + Bu@(Bi.T) + P@(Q.T)\n",
    "\n",
    "        # Calculate gradient only respect to know ratings\n",
    "        pred = pred_mat[uir_mat[:, 0], uir_mat[:, 1]]\n",
    "\n",
    "#         loss = criterion(pred, expected)\n",
    "        # Regularized rmse\n",
    "#         loss = 1/(2*n_interactions) * torch.sum((pred - expected)**2)\n",
    "        loss = 1/(2*n_interactions) * torch.sum((pred - expected)**2) + 位*(torch.sum(P**2) + torch.sum(Q**2))\n",
    "        train_losses[i] = float(loss.detach())\n",
    "        \n",
    "        if min_loss > loss.detach():\n",
    "            min_loss = float(loss.detach())\n",
    "            params = [P.detach().cpu(), Q.detach().cpu(), bu.detach().cpu(), bi.detach().cpu()]\n",
    "#             print(f\"iter {i+1}: {min_loss}\")\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Validation error\n",
    "            if uir_val is not None:\n",
    "                pred_val = pred_mat[uir_val[:, 0], uir_val[:, 1]]\n",
    "                const = 1/(2*n_interactions_val)\n",
    "                val_loss = const * torch.sum((pred_val - expected_val)**2) + 位/2*(torch.sum(P**2) + torch.sum(Q**2))\n",
    "                val_losses[i] = float(val_loss)\n",
    "            \n",
    "            P -= lr*P.grad\n",
    "            Q -= lr*Q.grad\n",
    "            bu -= lr*bu.grad\n",
    "            bi -= lr*bi.grad\n",
    "            \n",
    "        P.grad.zero_()\n",
    "        Q.grad.zero_()\n",
    "        bu.grad.zero_()\n",
    "        bi.grad.zero_()\n",
    "            \n",
    "    print(\"train:\", min_loss)\n",
    "    print(\"val:\", float(val_loss))\n",
    "    return params, train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36178b21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09f6205a33364b39a78b1441c4b9fdd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 0.6085423827171326\n",
      "val: inf\n"
     ]
    }
   ],
   "source": [
    "## Test\n",
    "mat = torch.tensor([\n",
    "    [5, 2, 4, 3, 2, 3],\n",
    "    [4, 3, 5, 4, 3, 2],\n",
    "    [1, 5, 3, 4, 4, 5],\n",
    "    [1, 0, 2, 3, 4, 2],\n",
    "], dtype=torch.float32)\n",
    "uir_test_mat = torch.zeros(mat.shape[0]*mat.shape[1] -1, 3, dtype=torch.long)\n",
    "k = 0\n",
    "for i in range(mat.shape[0]):\n",
    "    for j in range(mat.shape[1]):\n",
    "        if mat[i, j] != 0:\n",
    "            uir_test_mat[k] = torch.tensor([i, j, mat[i, j]])\n",
    "            k += 1\n",
    "\n",
    "(out_P, out_Q, out_bu, out_bi), _, _ = fit(\n",
    "    uir_mat=uir_test_mat, \n",
    "    k=3, \n",
    "    lr=0.08, \n",
    "    位=0.01, \n",
    "    iters=70, \n",
    "    n_users=4, \n",
    "    n_movies=6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed847ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.2375, 4.2106, 4.2071, 4.1784, 4.2153, 4.2005],\n",
      "        [4.1981, 4.2254, 4.2488, 4.2760, 4.2297, 4.2357],\n",
      "        [4.1518, 4.2458, 4.2871, 4.3826, 4.2468, 4.2799],\n",
      "        [4.3330, 4.1835, 4.1013, 3.9349, 4.1955, 4.1185]])\n",
      "\n",
      "tensor([[5., 2., 4., 3., 2., 3.],\n",
      "        [4., 3., 5., 4., 3., 2.],\n",
      "        [1., 5., 3., 4., 4., 5.],\n",
      "        [1., 0., 2., 3., 4., 2.]])\n"
     ]
    }
   ],
   "source": [
    "out_mat = reconstruct(out_P, out_Q, out_bu, out_bi, (mat.sum()/(mat!=0).sum()))\n",
    "\n",
    "print(out_mat)\n",
    "print()\n",
    "print(mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d417dc",
   "metadata": {},
   "source": [
    "# Real Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65e3f7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.typing import NDArray\n",
    "import pandas as pd\n",
    "from numba import njit, prange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cfb9acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = 3974\n",
    "movies = 3564\n",
    "\n",
    "train_csv = pd.read_csv(\"../../../data/train_data.csv\")\n",
    "test_csv = pd.read_csv(\"../../../data/test_data.csv\")\n",
    "\n",
    "train_csv[\"user_id\"] = train_csv[\"user_id\"].apply(lambda x: x - 1)\n",
    "train_csv[\"movie_id\"] = train_csv[\"movie_id\"].apply(lambda x: x - 1)\n",
    "\n",
    "test_csv[\"user_id\"] = test_csv[\"user_id\"].apply(lambda x: x - 1)\n",
    "test_csv[\"movie_id\"] = test_csv[\"movie_id\"].apply(lambda x: x - 1)\n",
    "\n",
    "# Split into train and validation\n",
    "train_data = train_csv.drop([\"timestamp\"], axis=1).sample(frac=0.8)\n",
    "validation_data = train_csv.drop(train_data.index).drop([\"timestamp\"], axis=1)\n",
    "\n",
    "assert train_data.shape[0] + validation_data.shape[0] == train_csv.shape[0]## Split into train and validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ded70cd",
   "metadata": {},
   "source": [
    "# Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ffaebda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe62f2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "uir_train = train_data.values\n",
    "mu_train = np.mean(uir_train[:, 2])\n",
    "uir_train_tensor = torch.from_numpy(uir_train)\n",
    "\n",
    "uir_val = validation_data.values\n",
    "n_val = uir_val.shape[0]\n",
    "uir_val_tensor = torch.from_numpy(uir_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfa21148",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ad366286c8341f086bd22f6b03124d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a966991832a4046b3884ee52faa1653",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 0.6689586639404297\n",
      "val: 0.6700192093849182\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60167d72815c4a958831f653610384e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 0.6626609563827515\n",
      "val: 0.6648584008216858\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e8e236cb1944598802efa6be412c4e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 0.6655436754226685\n",
      "val: 0.6686933040618896\n"
     ]
    }
   ],
   "source": [
    "min_err = np.inf\n",
    "best_k = 2\n",
    "# for k in tqdm(range(2, 4)):\n",
    "for k in tqdm(range(98, 101)):\n",
    "    fitted_params, tr_loss, v_loss = fit(\n",
    "        uir_mat=uir_train_tensor,\n",
    "        k=50,\n",
    "        lr=0.8, \n",
    "        位=0.01, \n",
    "        iters=1000, \n",
    "        n_users=users, \n",
    "        n_movies=movies, \n",
    "        mu=mu_train,\n",
    "        uir_val=uir_val_tensor,\n",
    "    )\n",
    "    recontructed_mat = reconstruct(*fitted_params, mu_train).numpy()\n",
    "    \n",
    "    predicted = recontructed_mat[uir_val[:, 0], uir_val[:, 1]]\n",
    "    \n",
    "#     predicted = predicted.round()\n",
    "    err = 1/(2*n_val) * np.sum((predicted - uir_val[:, 2])**2)\n",
    "    \n",
    "#     plt.plot(tr_loss[-300:])\n",
    "#     plt.plot(v_loss[-300:])\n",
    "#     plt.show()\n",
    "    \n",
    "    if min_err > err:\n",
    "        min_err = err\n",
    "        best_k = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef9ffa7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.6212215, 4.65078  , 4.646514 , 4.6297665, 4.716919 , 4.5182514,\n",
       "       4.5998006, 4.4203005, 4.709689 , 4.8711176, 4.6422086, 4.661655 ,\n",
       "       4.6558094, 4.5999665, 5.       , 4.7250853, 4.730851 , 4.671728 ,\n",
       "       4.649667 , 4.802049 , 5.       , 4.8535256, 5.       , 4.6428146,\n",
       "       4.6813803, 4.704528 , 4.7896814, 4.647318 , 4.60566  , 4.6171503,\n",
       "       4.641992 , 4.9300146, 5.       , 4.908063 , 4.701    , 4.7205634,\n",
       "       4.936112 , 4.7821484, 4.861743 , 4.6968956, 4.5826526, 4.738677 ,\n",
       "       4.8444386, 4.5223904, 4.9432487, 4.6296134, 4.486174 , 4.763527 ,\n",
       "       4.59197  , 4.883722 ], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82210686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 1.1370220181616322\n"
     ]
    }
   ],
   "source": [
    "print(best_k, min_err)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8cb49b",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd7c693a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9285c8ae1953429da0a1cd28c773b90e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 26.34429931640625\n",
      "val: inf\n"
     ]
    }
   ],
   "source": [
    "uir_full = train_csv.drop([\"timestamp\"], axis=1).values\n",
    "uir_full = torch.from_numpy(uir_full)\n",
    "mu_full = torch.mean(uir_full[:, 2].float())\n",
    "\n",
    "fitted_params = fit(\n",
    "    uir_mat=uir_full, k=best_k, lr=0.8, 位=0.01, iters=1, n_users=users, n_movies=movies, mu=mu_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "765d1b90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fitted_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "feda5516",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "reconstruct() missing 2 required positional arguments: 'bi' and 'mu'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m recontructed_mat \u001b[38;5;241m=\u001b[39m \u001b[43mreconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfitted_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "\u001b[0;31mTypeError\u001b[0m: reconstruct() missing 2 required positional arguments: 'bi' and 'mu'"
     ]
    }
   ],
   "source": [
    "recontructed_mat = reconstruct(*fitted_params, mu=mu_full).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6471aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_predictions = predict_batch(\n",
    "#     test_csv.drop([\"id\", \"timestamp\"], axis=1).values,\n",
    "#     recontructed_mat,\n",
    "# )\n",
    "uir_test = test_csv.drop([\"id\", \"timestamp\"], axis=1).values\n",
    "test_predictions = recontructed_mat[uir_test[:, 0], uir_test[:, 1]]\n",
    "print(test_predictions[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2154ad48",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        \"id\": list(test_csv[\"id\"]),\n",
    "        \"rating\": test_predictions\n",
    "    }\n",
    ")\n",
    "\n",
    "out_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cfbf0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df.to_csv(\"out_funk_svd_1.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
