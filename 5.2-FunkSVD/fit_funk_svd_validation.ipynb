{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07182b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from typing import List\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fd325c",
   "metadata": {},
   "source": [
    "## Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef0b236d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct(\n",
    "    P: torch.FloatTensor,\n",
    "    Q: torch.FloatTensor,\n",
    "    bu: torch.FloatTensor,\n",
    "    bi: torch.FloatTensor,\n",
    "    mu: float,\n",
    ") -> torch.FloatTensor:\n",
    "    P = P.cuda()\n",
    "    Q = Q.cuda()\n",
    "    bu = bu.cuda()\n",
    "    bi = bi.cuda()\n",
    "    \n",
    "    Bu = torch.concat((bu, torch.ones(len(bu), 1, device=\"cuda\")), dim=1)\n",
    "    Bi = torch.concat((bi, torch.ones(len(bi), 1, device=\"cuda\")), dim=1)\n",
    "    \n",
    "    mat = mu + Bu@Bi.T + P@Q.T\n",
    "    \n",
    "    return torch.clip(mat, 1, 5).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "23f77b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(\n",
    "    uir_mat: torch.IntTensor, # User Item rating mat\n",
    "    k: int,\n",
    "    lr: float,\n",
    "    λ: float,\n",
    "    iters: int,\n",
    "    n_users: int,\n",
    "    n_movies: int,\n",
    "    mu: float = None,\n",
    "    uir_val: torch.IntTensor = None\n",
    ") -> List[torch.FloatTensor]:\n",
    "    train_losses = np.zeros(iters)\n",
    "    val_losses = np.zeros(iters)\n",
    "    \n",
    "    # Initialize params\n",
    "    uir_mat = uir_mat.cuda()\n",
    "    expected = uir_mat[:, 2].float()\n",
    "    n_interactions = expected.shape[0]\n",
    "    \n",
    "    if uir_val is not None:\n",
    "        uir_val = uir_val.cuda()\n",
    "        expected_val = uir_val[:, 2].float()\n",
    "        n_interactions_val = expected_val.shape[0]\n",
    "    \n",
    "    P = torch.rand(n_users, k, requires_grad=True, device=\"cuda\")\n",
    "    Q = torch.rand(n_movies, k, requires_grad=True, device=\"cuda\")\n",
    "    bu = torch.rand(n_users, 1, requires_grad=True, device=\"cuda\")\n",
    "    bi = torch.rand(n_movies, 1, requires_grad=True, device=\"cuda\")\n",
    "    \n",
    "    if mu is None:\n",
    "        mu = (expected.sum()/(expected!=0).sum())\n",
    "\n",
    "#     criterion = nn.MSELoss()\n",
    "    \n",
    "    # Fit\n",
    "    ones_user = torch.ones(n_users, 1, requires_grad=False, device=\"cuda\")\n",
    "    ones_item = torch.ones(n_movies, 1, requires_grad=False, device=\"cuda\")\n",
    "\n",
    "    min_loss = torch.inf\n",
    "    params = []\n",
    "    \n",
    "    val_loss = torch.inf\n",
    "    for i in tqdm(range(iters)):\n",
    "        Bu = torch.concat((bu, ones_user), dim=1)\n",
    "        Bi = torch.concat((bi, ones_item), dim=1)\n",
    "\n",
    "        pred_mat = mu + Bu@(Bi.T) + P@(Q.T)\n",
    "\n",
    "        # Calculate gradient only respect to know ratings\n",
    "        pred = pred_mat[uir_mat[:, 0], uir_mat[:, 1]]\n",
    "\n",
    "#         loss = criterion(pred, expected)\n",
    "        # Regularized rmse\n",
    "#         loss = 1/(2*n_interactions) * torch.sum((pred - expected)**2)\n",
    "        loss = 1/(2*n_interactions) * torch.sum((pred - expected)**2) + λ*(torch.sum(P**2) + torch.sum(Q**2))\n",
    "        train_losses[i] = float(loss.detach())\n",
    "        \n",
    "        if min_loss > loss.detach():\n",
    "            min_loss = float(loss.detach())\n",
    "            params = [P.detach().cpu(), Q.detach().cpu(), bu.detach().cpu(), bi.detach().cpu()]\n",
    "#             print(f\"iter {i+1}: {min_loss}\")\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Validation error\n",
    "            if uir_val is not None:\n",
    "                pred_val = pred_mat[uir_val[:, 0], uir_val[:, 1]]\n",
    "                const = 1/(2*n_interactions_val)\n",
    "                val_loss = const * torch.sum((pred_val - expected_val)**2) + λ/2*(torch.sum(P**2) + torch.sum(Q**2))\n",
    "                val_losses[i] = float(val_loss)\n",
    "            \n",
    "            P -= lr*P.grad\n",
    "            Q -= lr*Q.grad\n",
    "            bu -= lr*bu.grad\n",
    "            bi -= lr*bi.grad\n",
    "            \n",
    "        P.grad.zero_()\n",
    "        Q.grad.zero_()\n",
    "        bu.grad.zero_()\n",
    "        bi.grad.zero_()\n",
    "            \n",
    "    print(\"train:\", min_loss)\n",
    "    print(\"val:\", float(val_loss))\n",
    "    return params, train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "36178b21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2da28e689dcf45fc9c79d4437e37e7e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 0.7445540428161621\n",
      "val: inf\n"
     ]
    }
   ],
   "source": [
    "## Test\n",
    "mat = torch.tensor([\n",
    "    [5, 2, 4, 3, 2, 3],\n",
    "    [4, 3, 5, 4, 3, 2],\n",
    "    [1, 5, 3, 4, 4, 5],\n",
    "    [1, 0, 2, 3, 4, 2],\n",
    "], dtype=torch.float32)\n",
    "uir_test_mat = torch.zeros(mat.shape[0]*mat.shape[1] -1, 3, dtype=torch.long)\n",
    "k = 0\n",
    "for i in range(mat.shape[0]):\n",
    "    for j in range(mat.shape[1]):\n",
    "        if mat[i, j] != 0:\n",
    "            uir_test_mat[k] = torch.tensor([i, j, mat[i, j]])\n",
    "            k += 1\n",
    "\n",
    "(out_P, out_Q, out_bu, out_bi), _, _ = fit(\n",
    "    uir_mat=uir_test_mat, \n",
    "    k=3, \n",
    "    lr=0.08, \n",
    "    λ=0.01, \n",
    "    iters=70, \n",
    "    n_users=4, \n",
    "    n_movies=6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed847ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.1269, 4.0524, 4.0122, 4.1652, 3.8172, 4.0693],\n",
      "        [3.9715, 4.1880, 4.2214, 4.1969, 3.8973, 4.1179],\n",
      "        [3.9735, 4.2799, 4.1403, 4.0378, 4.4103, 4.1109],\n",
      "        [3.2400, 4.0822, 3.3688, 3.4950, 3.6672, 3.4347]])\n",
      "\n",
      "tensor([[5., 2., 4., 3., 2., 3.],\n",
      "        [4., 3., 5., 4., 3., 2.],\n",
      "        [1., 5., 3., 4., 4., 5.],\n",
      "        [1., 0., 2., 3., 4., 2.]])\n"
     ]
    }
   ],
   "source": [
    "out_mat = reconstruct(out_P, out_Q, out_bu, out_bi, (mat.sum()/(mat!=0).sum()))\n",
    "\n",
    "print(out_mat)\n",
    "print()\n",
    "print(mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d417dc",
   "metadata": {},
   "source": [
    "# Real Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65e3f7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.typing import NDArray\n",
    "import pandas as pd\n",
    "from numba import njit, prange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cfb9acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = 3974\n",
    "movies = 3564\n",
    "\n",
    "train_csv = pd.read_csv(\"../../data/train_data.csv\")\n",
    "test_csv = pd.read_csv(\"../../data/test_data.csv\")\n",
    "\n",
    "train_csv[\"user_id\"] = train_csv[\"user_id\"].apply(lambda x: x - 1)\n",
    "train_csv[\"movie_id\"] = train_csv[\"movie_id\"].apply(lambda x: x - 1)\n",
    "\n",
    "test_csv[\"user_id\"] = test_csv[\"user_id\"].apply(lambda x: x - 1)\n",
    "test_csv[\"movie_id\"] = test_csv[\"movie_id\"].apply(lambda x: x - 1)\n",
    "\n",
    "# Split into train and validation\n",
    "train_data = train_csv.drop([\"timestamp\"], axis=1).sample(frac=0.8)\n",
    "validation_data = train_csv.drop(train_data.index).drop([\"timestamp\"], axis=1)\n",
    "\n",
    "assert train_data.shape[0] + validation_data.shape[0] == train_csv.shape[0]## Split into train and validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ded70cd",
   "metadata": {},
   "source": [
    "# Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ffaebda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe62f2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "uir_train = train_data.values\n",
    "mu_train = np.mean(uir_train[:, 2])\n",
    "uir_train_tensor = torch.from_numpy(uir_train)\n",
    "\n",
    "uir_val = validation_data.values\n",
    "n_val = uir_val.shape[0]\n",
    "uir_val_tensor = torch.from_numpy(uir_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bfa21148",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a93a4ea31af410d8247e41a7b53faaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0cbac458b27412c9486ff74a2047745",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 1.1619596481323242\n",
      "val: 1.1594502925872803\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58791d898168491db38d7ec7c752c8fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 1.1649868488311768\n",
      "val: 1.162549614906311\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "302e73a2560d4f3eac035b08bf9c83a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 1.1605204343795776\n",
      "val: 1.1594702005386353\n"
     ]
    }
   ],
   "source": [
    "min_err = np.inf\n",
    "best_k = 2\n",
    "# for k in tqdm(range(2, 4)):\n",
    "for k in tqdm(range(98, 101)):\n",
    "    fitted_params, tr_loss, v_loss = fit(\n",
    "        uir_mat=uir_train_tensor,\n",
    "        k=50,\n",
    "        lr=0.8, \n",
    "        λ=0.01, \n",
    "        iters=1000, \n",
    "        n_users=users, \n",
    "        n_movies=movies, \n",
    "        mu=mu_train,\n",
    "        uir_val=uir_val_tensor,\n",
    "    )\n",
    "    recontructed_mat = reconstruct(*fitted_params, mu_train).numpy()\n",
    "    \n",
    "    predicted = recontructed_mat[uir_val[:, 0], uir_val[:, 1]]\n",
    "    \n",
    "#     predicted = predicted.round()\n",
    "    err = 1/(2*n_val) * np.sum((predicted - uir_val[:, 2])**2)\n",
    "    \n",
    "#     plt.plot(tr_loss[-300:])\n",
    "#     plt.plot(v_loss[-300:])\n",
    "#     plt.show()\n",
    "    \n",
    "    if min_err > err:\n",
    "        min_err = err\n",
    "        best_k = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef9ffa7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.573386 , 4.28248  , 4.6106195, 4.8903956, 4.808412 , 4.968319 ,\n",
       "       5.       , 4.587598 , 4.934968 , 4.6399937, 4.7482495, 4.7073774,\n",
       "       4.7198052, 4.7356224, 4.755826 , 4.5733213, 4.613162 , 4.493431 ,\n",
       "       4.4028664, 4.5966983, 4.60465  , 4.5945363, 4.4754615, 4.7571745,\n",
       "       4.8311214, 4.567875 , 4.706207 , 4.861495 , 4.760673 , 4.8656297,\n",
       "       4.8634467, 4.7906184, 4.840976 , 4.6481967, 4.698329 , 4.82633  ,\n",
       "       4.900764 , 5.       , 4.8186274, 4.8785615, 4.685965 , 4.668737 ,\n",
       "       5.       , 4.8909073, 4.541462 , 4.3416266, 4.703979 , 4.8090878,\n",
       "       5.       , 4.7518473], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82210686",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_k, min_err)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8cb49b",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7c693a",
   "metadata": {},
   "outputs": [],
   "source": [
    "uir_full = train_csv.drop([\"timestamp\"], axis=1).values\n",
    "uir_full = torch.from_numpy(uir_full)\n",
    "mu_full = torch.mean(uir_full[:, 2].float())\n",
    "\n",
    "fitted_params = fit(\n",
    "    uir_mat=uir_full, k=best_k, lr=0.8, λ=0.01, iters=10000, n_users=users, n_movies=movies, mu=mu_full)\n",
    "recontructed_mat = reconstruct(*fitted_params, mu_full).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6471aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_predictions = predict_batch(\n",
    "#     test_csv.drop([\"id\", \"timestamp\"], axis=1).values,\n",
    "#     recontructed_mat,\n",
    "# )\n",
    "uir_test = test_csv.drop([\"id\", \"timestamp\"], axis=1).values\n",
    "test_predictions = recontructed_mat[uir_test[:, 0], uir_test[:, 1]]\n",
    "print(test_predictions[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2154ad48",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        \"id\": list(test_csv[\"id\"]),\n",
    "        \"rating\": test_predictions\n",
    "    }\n",
    ")\n",
    "\n",
    "out_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cfbf0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df.to_csv(\"out_funk_svd_1.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
