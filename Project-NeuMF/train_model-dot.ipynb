{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70493b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.models_dot import GMF, MLP, NeuFM\n",
    "from utils.dataset import RatingsDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5390e831",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d731681",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7610d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = 3974\n",
    "movies = 3564\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    RatingsDataset(\n",
    "        \"train_data/train.csv\",\n",
    "        \"user_id\",\n",
    "        \"movie_id\",\n",
    "        \"rating\",\n",
    "    ), \n",
    "    batch_size=1024,\n",
    "    num_workers=8,\n",
    "    shuffle=True,\n",
    ")\n",
    "val_dataloader = DataLoader(\n",
    "    RatingsDataset(\n",
    "        \"train_data/validation.csv\",\n",
    "        \"user_id\",\n",
    "        \"movie_id\",\n",
    "        \"rating\",\n",
    "    ),\n",
    "    batch_size=1024,\n",
    "    num_workers=4,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15cc5942",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6837dd1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f48f40a0110>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9fc0112d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuFM(\n",
       "  (gmf): GMF(\n",
       "    (P): Embedding(3974, 16)\n",
       "    (Q): Embedding(3564, 16)\n",
       "  )\n",
       "  (mlp): MLP(\n",
       "    (P): Embedding(3974, 16)\n",
       "    (Q): Embedding(3564, 16)\n",
       "    (layers): ModuleList(\n",
       "      (0): Linear(in_features=32, out_features=16, bias=True)\n",
       "      (1): Linear(in_features=16, out_features=8, bias=True)\n",
       "    )\n",
       "    (h): Linear(in_features=8, out_features=1, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuFM(\n",
    "    GMF(users, movies, 16),\n",
    "    MLP(users, movies, 16, [16, 8]),\n",
    "    alpha=0.5,\n",
    ").cuda()\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8651966e",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e1e5824",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89a75fe622eb4f48a6378ff11e907703",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train_loss: 2.956326577171081, val_loss: 1.1161064901715423\n",
      "epoch: 1, train_loss: 1.0035022194643075, val_loss: 0.9561162859263271\n",
      "epoch: 2, train_loss: 0.9288072963526742, val_loss: 0.9236659219532888\n",
      "epoch: 3, train_loss: 0.9073647238664276, val_loss: 0.9109747109041914\n",
      "epoch: 4, train_loss: 0.896532083944644, val_loss: 0.9036692045590853\n",
      "epoch: 5, train_loss: 0.8889849994819201, val_loss: 0.8982821873242268\n",
      "epoch: 6, train_loss: 0.8826675148167501, val_loss: 0.8942432890079535\n",
      "epoch: 7, train_loss: 0.8770832853939032, val_loss: 0.8903219043198978\n",
      "epoch: 8, train_loss: 0.8719390695069579, val_loss: 0.8876649836486495\n",
      "epoch: 9, train_loss: 0.8673854669597011, val_loss: 0.885112780472094\n",
      "epoch: 10, train_loss: 0.8634863441331718, val_loss: 0.8832531377777159\n",
      "epoch: 11, train_loss: 0.8596058190810888, val_loss: 0.8814296882799986\n",
      "epoch: 12, train_loss: 0.856179935249112, val_loss: 0.8798964143435043\n",
      "epoch: 13, train_loss: 0.8528883582675542, val_loss: 0.8786006573976052\n",
      "epoch: 14, train_loss: 0.8496573634754522, val_loss: 0.8775346129006077\n",
      "epoch: 15, train_loss: 0.8464816498064237, val_loss: 0.8763479748675177\n",
      "epoch: 16, train_loss: 0.8432899398596195, val_loss: 0.8750385942683804\n",
      "epoch: 17, train_loss: 0.8399977083900054, val_loss: 0.8740765202089799\n",
      "epoch: 18, train_loss: 0.8365545858858876, val_loss: 0.8726524938162167\n",
      "epoch: 19, train_loss: 0.8329179191210134, val_loss: 0.8718811068735983\n",
      "epoch: 20, train_loss: 0.8293393102231549, val_loss: 0.8704834601405925\n",
      "epoch: 21, train_loss: 0.8254846698777438, val_loss: 0.8695992371765672\n",
      "epoch: 22, train_loss: 0.8217432894070138, val_loss: 0.8684257121307364\n",
      "epoch: 23, train_loss: 0.8177567807361957, val_loss: 0.8674133038871331\n",
      "epoch: 24, train_loss: 0.8137406300283903, val_loss: 0.8671048442590468\n",
      "epoch: 25, train_loss: 0.8097838345453626, val_loss: 0.86638205980225\n",
      "epoch: 26, train_loss: 0.8057841598589816, val_loss: 0.8649608609819124\n",
      "epoch: 27, train_loss: 0.8017587115822226, val_loss: 0.8649554177694728\n",
      "epoch: 28, train_loss: 0.7978797585260443, val_loss: 0.8638677253147193\n",
      "epoch: 29, train_loss: 0.7939533803096755, val_loss: 0.8644779333877508\n",
      "epoch: 30, train_loss: 0.7901588286303228, val_loss: 0.8632759192715019\n",
      "epoch: 31, train_loss: 0.7862710252350686, val_loss: 0.863145514720056\n",
      "epoch: 32, train_loss: 0.7825973193049264, val_loss: 0.8629424083413358\n",
      "epoch: 33, train_loss: 0.7787925757899361, val_loss: 0.8629315932937924\n",
      "epoch: 34, train_loss: 0.7752257316473505, val_loss: 0.8630508511218957\n",
      "epoch: 35, train_loss: 0.7716307690531387, val_loss: 0.8633845411667614\n",
      "epoch: 36, train_loss: 0.7682175565610012, val_loss: 0.8641502302932729\n",
      "epoch: 37, train_loss: 0.7648256386067015, val_loss: 0.8639176306216989\n",
      "epoch: 38, train_loss: 0.7615253093315185, val_loss: 0.8642620490397365\n",
      "epoch: 39, train_loss: 0.7582900339131212, val_loss: 0.8646611598126771\n",
      "epoch: 40, train_loss: 0.7552266940751959, val_loss: 0.8652177108202497\n",
      "epoch: 41, train_loss: 0.7522262028836851, val_loss: 0.865656549947567\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m val_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Train step\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i_batch, (vus, vis, rs) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_dataloader):\n\u001b[1;32m     12\u001b[0m     vus \u001b[38;5;241m=\u001b[39m vus\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m     13\u001b[0m     vis \u001b[38;5;241m=\u001b[39m vis\u001b[38;5;241m.\u001b[39mcuda()\n",
      "File \u001b[0;32m~/anaconda3/envs/scicomp/lib/python3.10/site-packages/torch/utils/data/dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    529\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[0;32m--> 530\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    533\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    534\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/scicomp/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1207\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1204\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1206\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1207\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1208\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1210\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/scicomp/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1173\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1169\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1170\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1171\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1172\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1173\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1174\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1175\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/anaconda3/envs/scicomp/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1011\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    998\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m    999\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1000\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1008\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1009\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1010\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1011\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1012\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1013\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1014\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1015\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1016\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/scicomp/lib/python3.10/multiprocessing/queues.py:122\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rlock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    121\u001b[0m \u001b[38;5;66;03m# unserialize the data after having released the lock\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ForkingPickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/scicomp/lib/python3.10/site-packages/torch/multiprocessing/reductions.py:295\u001b[0m, in \u001b[0;36mrebuild_storage_fd\u001b[0;34m(cls, df, size)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrebuild_storage_fd\u001b[39m(\u001b[38;5;28mcls\u001b[39m, df, size):\n\u001b[0;32m--> 295\u001b[0m     fd \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    297\u001b[0m         storage \u001b[38;5;241m=\u001b[39m storage_from_cache(\u001b[38;5;28mcls\u001b[39m, fd_id(fd))\n",
      "File \u001b[0;32m~/anaconda3/envs/scicomp/lib/python3.10/multiprocessing/resource_sharer.py:57\u001b[0m, in \u001b[0;36mDupFd.detach\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdetach\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;124;03m'''Get the fd.  This should only be called once.'''\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_resource_sharer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_id\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m conn:\n\u001b[1;32m     58\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m reduction\u001b[38;5;241m.\u001b[39mrecv_handle(conn)\n",
      "File \u001b[0;32m~/anaconda3/envs/scicomp/lib/python3.10/multiprocessing/resource_sharer.py:86\u001b[0m, in \u001b[0;36m_ResourceSharer.get_connection\u001b[0;34m(ident)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconnection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Client\n\u001b[1;32m     85\u001b[0m address, key \u001b[38;5;241m=\u001b[39m ident\n\u001b[0;32m---> 86\u001b[0m c \u001b[38;5;241m=\u001b[39m \u001b[43mClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43maddress\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauthkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauthkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m c\u001b[38;5;241m.\u001b[39msend((key, os\u001b[38;5;241m.\u001b[39mgetpid()))\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m c\n",
      "File \u001b[0;32m~/anaconda3/envs/scicomp/lib/python3.10/multiprocessing/connection.py:513\u001b[0m, in \u001b[0;36mClient\u001b[0;34m(address, family, authkey)\u001b[0m\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauthkey should be a byte string\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m authkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 513\u001b[0m     \u001b[43manswer_challenge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauthkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    514\u001b[0m     deliver_challenge(c, authkey)\n\u001b[1;32m    516\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m c\n",
      "File \u001b[0;32m~/anaconda3/envs/scicomp/lib/python3.10/multiprocessing/connection.py:757\u001b[0m, in \u001b[0;36manswer_challenge\u001b[0;34m(connection, authkey)\u001b[0m\n\u001b[1;32m    754\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(authkey, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[1;32m    755\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    756\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAuthkey must be bytes, not \u001b[39m\u001b[38;5;132;01m{0!s}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mtype\u001b[39m(authkey)))\n\u001b[0;32m--> 757\u001b[0m message \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m)\u001b[49m         \u001b[38;5;66;03m# reject large message\u001b[39;00m\n\u001b[1;32m    758\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m message[:\u001b[38;5;28mlen\u001b[39m(CHALLENGE)] \u001b[38;5;241m==\u001b[39m CHALLENGE, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage = \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m message\n\u001b[1;32m    759\u001b[0m message \u001b[38;5;241m=\u001b[39m message[\u001b[38;5;28mlen\u001b[39m(CHALLENGE):]\n",
      "File \u001b[0;32m~/anaconda3/envs/scicomp/lib/python3.10/multiprocessing/connection.py:221\u001b[0m, in \u001b[0;36m_ConnectionBase.recv_bytes\u001b[0;34m(self, maxlength)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m maxlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m maxlength \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnegative maxlength\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 221\u001b[0m buf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recv_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaxlength\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m buf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bad_message_length()\n",
      "File \u001b[0;32m~/anaconda3/envs/scicomp/lib/python3.10/multiprocessing/connection.py:419\u001b[0m, in \u001b[0;36mConnection._recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_recv_bytes\u001b[39m(\u001b[38;5;28mself\u001b[39m, maxsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 419\u001b[0m     buf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    420\u001b[0m     size, \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39munpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m!i\u001b[39m\u001b[38;5;124m\"\u001b[39m, buf\u001b[38;5;241m.\u001b[39mgetvalue())\n\u001b[1;32m    421\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m size \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/scicomp/lib/python3.10/multiprocessing/connection.py:384\u001b[0m, in \u001b[0;36mConnection._recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    382\u001b[0m remaining \u001b[38;5;241m=\u001b[39m size\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m remaining \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 384\u001b[0m     chunk \u001b[38;5;241m=\u001b[39m \u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    385\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(chunk)\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "criterion = nn.MSELoss().cuda()\n",
    "optimizer = opt.Adam(model.parameters(), lr=0.0005)\n",
    "\n",
    "prev_val_loss = math.inf\n",
    "for epoch in tqdm(range(50)):\n",
    "    n_batches = len(train_dataloader)\n",
    "    avg_loss = 0\n",
    "    val_loss = 0\n",
    "    \n",
    "    # Train step\n",
    "    for i_batch, (vus, vis, rs) in enumerate(train_dataloader):\n",
    "        vus = vus.cuda()\n",
    "        vis = vis.cuda()\n",
    "        rs = rs.cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        y_hat = model(vus, vis)\n",
    "        \n",
    "        loss = criterion(y_hat, rs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        avg_loss += math.sqrt(float(loss.detach().cpu()))\n",
    "        \n",
    "    # Val step\n",
    "    with torch.no_grad():\n",
    "        for val_vus, val_vis, val_rs in val_dataloader:\n",
    "            val_vus = val_vus.cuda()\n",
    "            val_vis = val_vis.cuda()\n",
    "            val_rs = val_rs.cuda()\n",
    "\n",
    "            val_pred = model(val_vus, val_vis)\n",
    "            val_loss += math.sqrt(float(criterion(val_pred, val_rs).detach().cpu()))\n",
    "                \n",
    "    val_loss /= len(val_dataloader)\n",
    "    print(f\"epoch: {epoch}, train_loss: {avg_loss/n_batches}, val_loss: {val_loss}\")\n",
    "    \n",
    "    if val_loss < prev_val_loss:\n",
    "        prev_val_loss = val_loss\n",
    "#         torch.save(\n",
    "#             model.state_dict(), \n",
    "#             f\"/home/nubol23/Documents/NCF_dot_weights/run_{run}/{epoch}-{val_loss}.pt\"\n",
    "#         )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccf3627",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88027600",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_weights = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5ece62",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = NeuFM(\n",
    "    GMF(users, movies, 16),\n",
    "    MLP(users, movies, 16, [16, 8]),\n",
    "    alpha=0.5,\n",
    ").cuda()\n",
    "\n",
    "trained_model.load_state_dict(\n",
    "    torch.load(\n",
    "        f\"/home/nubol23/Documents/NCF_dot_weights/run_{run}/{trained_weights}\"\n",
    "    )\n",
    ")\n",
    "trained_model.cuda().eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abe5656",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(\n",
    "    RatingsDataset(\n",
    "        \"train_data/test.csv\",\n",
    "        \"user_id\",\n",
    "        \"movie_id\",\n",
    "    ), \n",
    "    batch_size=1024,\n",
    "    num_workers=12\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3773d6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = []\n",
    "\n",
    "for vus, vis in test_dataloader:\n",
    "    vus = vus.cuda()\n",
    "    vis = vis.cuda()\n",
    "\n",
    "    pred = torch.clip(trained_model(vus, vis), 1, 5).cpu().ravel().tolist()\n",
    "    test_predictions += pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4791fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test_csv = pd.read_csv(\"../../data/test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c99358",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "out_df = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        \"id\": list(test_csv[\"id\"]),\n",
    "        \"rating\": test_predictions\n",
    "    }\n",
    ")\n",
    "\n",
    "out_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2229019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# out_df.to_csv(f\"outputs_csv/neumf_5.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
