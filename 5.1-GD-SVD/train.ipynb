{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7df98a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "678ef385",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mat = torch.tensor([\n",
    "    [5, 2, 4, 3, 2, 3],\n",
    "    [4, 3, 5, 4, 3, 2],\n",
    "    [1, 5, 3, 4, 4, 5],\n",
    "    [1, 0, 2, 3, 4, 2],\n",
    "], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e88295ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users = test_mat.shape[0]\n",
    "n_movies = test_mat.shape[1]\n",
    "k = 3\n",
    "\n",
    "P = torch.rand(n_users, k, requires_grad=True, device=\"cuda\")\n",
    "Q = torch.rand(n_movies, k, requires_grad=True, device=\"cuda\")\n",
    "bu = torch.rand(n_users, 1, requires_grad=True, device=\"cuda\")\n",
    "bi = torch.rand(n_movies, 1, requires_grad=True, device=\"cuda\")\n",
    "\n",
    "mu = (test_mat.sum()/(test_mat!=0).sum())\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "expected = test_mat.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0b05b62",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "571b9ce383c44901bb61024f4222778c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.815906524658203\n",
      "5.760279655456543\n",
      "5.653106689453125\n",
      "5.498923301696777\n",
      "5.304213047027588\n",
      "5.078001976013184\n",
      "4.828884124755859\n",
      "4.567636013031006\n",
      "4.30161714553833\n",
      "4.038580894470215\n",
      "3.7856173515319824\n",
      "3.547283887863159\n",
      "3.327199935913086\n",
      "3.1278090476989746\n",
      "2.949627637863159\n",
      "2.7935123443603516\n",
      "2.6581802368164062\n",
      "2.542518138885498\n",
      "2.444793224334717\n",
      "2.363454818725586\n",
      "2.2961463928222656\n",
      "2.240525007247925\n",
      "2.194373607635498\n",
      "2.1551785469055176\n",
      "2.120570659637451\n",
      "2.0874528884887695\n",
      "2.0530571937561035\n",
      "2.014777660369873\n",
      "1.9694818258285522\n",
      "1.9147355556488037\n",
      "1.847806692123413\n",
      "1.767179250717163\n",
      "1.672750473022461\n",
      "1.5654308795928955\n",
      "1.447908639907837\n",
      "1.3254187107086182\n",
      "1.2046213150024414\n",
      "1.0952690839767456\n",
      "1.0078500509262085\n",
      "0.9529324769973755\n",
      "0.9407093524932861\n",
      "0.9766510725021362\n",
      "1.0614789724349976\n",
      "1.1885228157043457\n",
      "1.3424434661865234\n",
      "1.5012110471725464\n",
      "1.6367125511169434\n",
      "1.7181706428527832\n",
      "1.7239031791687012\n",
      "1.6405357122421265\n",
      "1.4742152690887451\n",
      "1.2520241737365723\n",
      "1.014551043510437\n",
      "0.8154513835906982\n",
      "0.7129956483840942\n",
      "0.7476571798324585\n",
      "0.9356557130813599\n",
      "1.257828950881958\n",
      "1.6584504842758179\n",
      "2.05246901512146\n",
      "2.3477656841278076\n",
      "2.467949151992798\n",
      "2.3740499019622803\n",
      "2.102808713912964\n",
      "1.7399160861968994\n",
      "1.4195760488510132\n",
      "1.2748620510101318\n",
      "1.3915023803710938\n",
      "1.7627356052398682\n",
      "2.284771680831909\n",
      "2.7707440853118896\n",
      "3.0242223739624023\n",
      "2.923431158065796\n",
      "2.476840019226074\n",
      "1.8519790172576904\n",
      "1.2930036783218384\n",
      "1.0464311838150024\n",
      "1.2328412532806396\n",
      "1.7731680870056152\n",
      "2.4193167686462402\n",
      "2.8470797538757324\n",
      "2.8185527324676514\n",
      "2.3312623500823975\n",
      "1.6017742156982422\n",
      "1.0156588554382324\n",
      "0.9006752967834473\n",
      "1.3578156232833862\n",
      "2.178819417953491\n",
      "2.922682762145996\n",
      "3.1817989349365234\n",
      "2.797499179840088\n",
      "2.0125293731689453\n",
      "1.3094747066497803\n",
      "1.16142737865448\n",
      "1.7067397832870483\n",
      "2.653984785079956\n",
      "3.4220569133758545\n",
      "3.524820327758789\n",
      "2.8941221237182617\n",
      "1.9443891048431396\n"
     ]
    }
   ],
   "source": [
    "lr = 0.008\n",
    "ones_user = torch.ones(n_users, 1, requires_grad=False, device=\"cuda\")\n",
    "ones_item = torch.ones(n_movies, 1, requires_grad=False, device=\"cuda\")\n",
    "\n",
    "min_loss = torch.inf\n",
    "params = []\n",
    "for i in tqdm(range(100)):\n",
    "    Bu = torch.concat((bu, ones_user), dim=1)\n",
    "    Bi = torch.concat((bi, ones_item), dim=1)\n",
    "    \n",
    "    pred = mu + Bu@(Bi.T) + P@(Q.T)\n",
    "    \n",
    "    loss = criterion(pred, expected)\n",
    "    print(float(loss))\n",
    "    if min_loss > loss.detach():\n",
    "        min_loss = float(loss.detach())\n",
    "        params = [P.detach().cpu(), Q.detach().cpu(), bu.detach().cpu(), bi.detach().cpu()]\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        P -= lr*P.grad\n",
    "        Q -= lr*Q.grad\n",
    "        bu -= lr*bu.grad\n",
    "        bi -= lr*bi.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4bf3f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7129956483840942\n",
      "[tensor([[-1.0555, -2.4306, -1.2819],\n",
      "        [-0.7446, -1.8783, -1.2457],\n",
      "        [-3.2433, -1.9906, -0.1469],\n",
      "        [-4.3032, -3.4648, -2.3825]]), tensor([[ 1.6477, -0.5807, -0.7546],\n",
      "        [-0.3543, -0.0238,  0.4515],\n",
      "        [ 0.4147, -0.0974, -0.0741],\n",
      "        [-0.2958,  0.3857, -0.2541],\n",
      "        [-0.1695,  0.9232,  0.0155],\n",
      "        [-0.3522,  0.3861,  1.0840]]), tensor([[-1.9964],\n",
      "        [-1.5842],\n",
      "        [-0.8658],\n",
      "        [-3.9659]]), tensor([[-0.1801],\n",
      "        [ 0.9815],\n",
      "        [-0.1303],\n",
      "        [ 0.5197],\n",
      "        [ 0.0578],\n",
      "        [ 0.1122]])]\n"
     ]
    }
   ],
   "source": [
    "print(min_loss)\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02978425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5.0000, 2.1110, 4.3714, 2.8802, 2.0172, 2.0370],\n",
      "        [5.0000, 2.4086, 4.3902, 3.2064, 2.4987, 2.2263],\n",
      "        [1.0000, 4.4978, 3.1898, 3.9965, 2.8772, 4.3347],\n",
      "        [1.6509, 1.0000, 3.4633, 2.6983, 1.4821, 1.3675]])\n",
      "\n",
      "tensor([[5., 2., 4., 3., 2., 3.],\n",
      "        [4., 3., 5., 4., 3., 2.],\n",
      "        [1., 5., 3., 4., 4., 5.],\n",
      "        [1., 0., 2., 3., 4., 2.]])\n"
     ]
    }
   ],
   "source": [
    "ones_user_cpu = torch.ones(n_users, 1, requires_grad=False)\n",
    "ones_item_cpu = torch.ones(n_movies, 1, requires_grad=False)\n",
    "\n",
    "out_P, out_Q, out_bu, out_bi = params\n",
    "out_Bu = torch.concat((out_bu, ones_user_cpu), dim=1)\n",
    "out_Bi = torch.concat((out_bi, ones_item_cpu), dim=1)\n",
    "\n",
    "out_mat = mu + out_Bu@out_Bi.T + out_P@out_Q.T\n",
    "out_mat = torch.clip(out_mat, 1, 5)\n",
    "\n",
    "print(out_mat)\n",
    "print()\n",
    "print(test_mat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
